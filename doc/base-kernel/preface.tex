\chapter{Preface}

\epigraph{The only way to avoid these traps is to encourage a software culture that knows that small is beautiful, that actively resists bloat and complexity: an engineering tradition that puts a high value on simple solutions, that looks for ways to break program systems up into small cooperating pieces}{Eric S. Raymond, The Art of UNIX Programming}


\section{Issues with Previous MyThOS Designs}

\begin{enumerate}[(1)]
\item The object capabilities were present as a translation table from user-visible logical identifiers to actual kernel-level pointers. However, these translations did not cooperate with the resource management. Hence, it was possible to delete kernel objects without cleaning up all dangling references. Deletion could overlap with concurrent method calls to the deleted object.
\item The object capabilities translated just to kernel objects and any access control was implemented by pointing to a more restricted interface. Combining all relevant access rights, for example readable, writeable, delegatable, referencable, and so on, leads to a combinatorial explosion of interface variants.
\item Each execution context (user thread) required a dedicated kernel stack that was used for the entry from system calls and interrupts. These stacks were mostly unused because the kernel's task scheduling had to switch to the hardware thread's main stack anyway. Allocating and mapping these kernel stacks into the kernel space increased the thread creation overhead. 
\item All kernel objects were placed into specific expandable logical address ranges in the kernel space. The implied dynamic kernel address space management introduced dependencies to physical memory allocators for the on-demand creation of page maps. This introduced non-deterministic overheads whenever the kernel space page maps had to be updated.
\item In order to improve the scalability of the kernel's internal memory allocators, private memory pools were used at each hardware thread. Because of the limited memory capacity, these pools had to allocate from a globally shared reserve anyway. The assignment of resources to these pools and the return to the global pool required complex policies, statistics, and algorithms. Nevertheless these strategies did not match the application's actual needs.
\item The implicitly allocated kernel-space objects had no user-visible address. Hence, there was no mechanism to clean up and recycle these resources on demand. Smart pointers with reference counting were used at some places but did not cooperate well with the translation of user capabilities to kernel objects. Especially, it was easy to create cyclic dependencies that would never get cleaned up. This could have been solved with a much more restrictive process-thread model, tying the kernel and supervisors to a quite limited policy.
\item The high-level stubs for system calls tried very hard to resemble a homogeneous symmetric remote method invocation model similar to, for example, JavaRMI. This made the actual implementation of kernel objects and services overly difficult because the generated kernel-side stubs either hid too much context information, for example the calling process and numeric object handles, or pre-processed the arguments more than actually needed by the kernel object. 
\item The generator for the high-level stubs increased dependencies on complex tools like the python-clang binding. Despite all the help from modern compilers, extracting interface definitions from the kernel's C++ code had a hard time to separate interface-relevant information from unrelated definitions. This polluted the user-space client stubs with arbitrary kernel-internal definitions. 
\item Like with the widely used locks for critical code sections, all synchronisation was in the responsibility of the users/callers of kernel objects and services like the address space management. However, often the caller side did not know the exact synchronisation requirements , or the correct core, that was supposed to process the requests. Therefore, some synchronisation was overly pessimistic while some was insufficient and led to race conditions.
\item The kernel-level asynchronous communication between hardware threads was unbounded based on the on-demand allocation of message buffers. This introduces hidden overheads for the allocation and deallocation of messages. The missing flow control allowed misbehaving code to use up all kernel memory. Likewise, the asynchronous inter-process communication service allowed misbehaving applications to deplete all kernel memory.
\item The kernel operated without masking the interrupts. All data structures based on atomic operations required careful design in order to avoid deadlocks created by interrupts at intermediate steps---especially when interrupt handlers might access the same data structures. Hence, complex wait-free data structures had to be used instead of simpler lock-free and obstruction-free variants. In consequence, interrupts had to be disabled at quite some places anyway.
\end{enumerate}


\section{Many-Core Challenges with Existing (Micro-)Kernel Architectures}

\begin{enumerate}[(a)]
\item Synchronous IPC and synchronous system calls: Long running operations such as resource cleanup, e.g.\ a capability revoke, block the calling thread. In order to offload such work to another thread, a complex combination of asynchronous notifications and user-level communication via shared memory is needed.
\item Big Kernel Lock versus fine grained locking versus replication: The Big Kernel Lock is a kernel monitor, which ensures that at any point of time at most one thread operates on the kernel's data. It simply sequentialises all system calls and interrupt handling and enables the use of very efficient low-overhead data structures and algorithms. However, the parallel scalability is obviously limited. Fine grained locking and nonblocking data structures reduce the serial fraction but increase the management overhead (space for locks, frequent acquire\&release operations) considerably. Multikernel and Clustered Multikernel exploit the big kernel lock's efficiency locally and use a higher message-based coordination layer globally. The scalability depends on the throughput of the replication mechanism.
\item Read-Copy-Update: This mechanism provides a quite restricted form of transactional memory and is well suited to increase the throughput of write operations on queues, lists, and trees. Is not a general purpose synchronisation mechanism and, hence for example, most critical sections in Linux still have to rely on (spin-) locks for mutual exclusion. The delayed visibility of the newest copy and delayed deletion of outdated copies implies the need for on-demand memory allocation for new copies. This introduces a dependency to a shared memory pool for these copies.
\item Frequent address space switching: 
\item Not all microkernels are as small and simple as desirable for many-core processors: Kernel-level on-demand memory allocation and deallocation add considerable complexity. The separation between core kernel components and platform- and application-specific extensions is not always clear, which hampers the extensibility.
\item Licensing: While some kernels are available under BSD-alike licenses, we repeatedly found crucial code under GPL license, for example in code generators for stubs and data structure access.  
\end{enumerate}


\section{Key Aspects of the Presented Design}

\begin{itemize}
\item No on-demand memory allocation and deallocation inside the kernel: objects are created only through user requests (system calls) and the user supplies the needed memory pool.
\item No logical/virtual memory in the kernel space: after booting, the kernel's logical to physical address translation tables are not extended, which removes the need for on-demand page maps. The kernel operates inside a 4GiB direct-mapped address range, which removes the need to differentiate between physical and logical addresses and enables compact 32bit pointers.
\item No direct access to user-space memory: the user tells the kernel which frames will be used for sharing between kernel and user space. The kernel accesses the physical frames directly, which removes all in-kernel page faults and dependency on the user-space address translation.
\item No interrupts during usual kernel-mode execution: Just the kernel's task scheduler contains a preemption point to check for pending interrupts. All kernel tasks are very short running or decompose into multiple tasks and can be implemented more efficiently when interrupts do not need to be feared.  
\item Unified smart pointer and weak reference mechanism, includes precise tracking of resource inheritance. This is used for long-term storage of references and enables to inform all affected reference holders and tear down all contained sub-resources.
\item Unified translation from user handles to kernel objects: Separate translation table implementations for the various types of user-visible kernel objects are no longer needed. Instead the user space references any type of kernel objects through capability pointers and these are translated into kernel objects and access rights through per-process capability spaces. The capability spaces are the user's entry point to the kernel's unified resource management and prevent premature deletion of kernel objects.
\item Simplified software layers: The synchronisation mechanisms do no longer need to differentiate between purely local synchronisation and remote communication. It is no longer necessary trying to choose a appropriate memory allocators in various places all over the kernel, which often fails because information about future sharing of the allocated memory is not available. Now, only factories for kernel objects allocate memory and are passed appropriate memory allocators by the caller.
\item No implicit sharing of kernel objects between processes, user threads, and hardware threads. Through the explicit allocation of kernel objects and user-driven partitioning of the physical memory pool, the applications have full control over all aspects of sharing.  
\item Non-blocking synchronisation in shared kernel objects: A delegation mechanism based on small task objects unifies various types of synchronisation monitors and provides lightweight non-blocking mutual exclusion. The monitors automate the flow control such that no on-demand allocation of message/task buffers is necessary.
\item Unified event-style task execution model: System calls, interrupt epilogues, delegated critical sections, asynchronous method calls, and the return to user-mode execution are expressed through small tasks and are scheduled by a lightweight scheduler on each hardware thread.
\item The kernel code does not hide that all addresses are in the direct mapped part of the kernel space. Physical addresses can be easily accessed by adding the direct mapping base address and physical addresses can be obtained from kernel addresses by subtraction.
\end{itemize}

\section{Relation to seL4}

It is undeniable that the design of \mythos as presented in this document borrowed many clever ideas from the seL4 design and implementation. We are very thankful for the inspiring papers and presentations of Gernot Heiser et al. and the decades of collective experience on which this work could build upon. Many projects, for instance also the Barrelfish multikernel, learned a lot from seL4, which helped to speed up development and allow to focus on specific key aspects. Despite the many similarities, \mythos features a few interesting differences, which we hope to be very useful for the targeted HPC application scenarios:  

\begin{itemize}
\item seL4's prefix serialisation of the capability derivation tree is used in \mythos for the prefix serialisation of the resource inheritance tree. We analysed the inheritance rules and successfully separated the tree management from any type-specific knowledge about kernel objects. Kernel objects implement a simple C++ interface in order to take part in the kernel's resource management.
\item seL4's compact storage of in-kernel pointers was applied to the resource inheritance tree in order to achieve a very compact representation even on 64-bit processors. By coincidence, the 64-bit variant does not consume more memory than seL4's 32-bit variant. 
\item \mythos replaces seL4's widespread use of switch-case type dispatches by C++ virtual methods of the kernel object interface. This enables the easy introduction of new kernel objects for specific use cases and hardware-specific device support. Whether the virtual method dispatch is faster than seL4's long chains of conditional branches has to be seen. Of course, such vtable-based dispatches complicate formal verification very much. 
\item The Untyped Memory objects in seL4 use a simple watermark scheme. This simplifies verification but leaves significant (internal) fragmentation when large kernel objects like page maps require a specific alignment. The \mythos design allows for the use of in-place free lists and similar heap structures inside the Untyped Memory objects. It still needs to be evaluated which variant balances overhead and compactness well enough.
\item Through the monitors and scheduling contexts, the \mythos kernel has an understanding of the processor's distributed topology. This makes it possible to assign kernel services and application threads to dedicated cores.
\item \mythos has no big kernel lock and allows concurrency inside the kernel. Lightweight non-blocking synchronisation and delegation are used to protect shared kernel objects. However, the decision to share kernel objects between hardware threads is a pure application choice. The kernel can be operated like a multikernel or a clustered multikernel. Of course, respective implementation variants should be selected to skip superfluous synchronisation.
\item Based on the scheduling contexts, the kernel's inter-process communication supports deferred synchronous communication between different hardware threads. Most L4-based kernels support just asynchronous notifications based on inter-process interrupts between hardware threads.
\item \mythos separates the sender-side communication portal from the user thread. This allows applications to set up multiple portals per thread in order to enable multiple overlapping deferred synchronous system calls and IPC messages. We hope that this simplifies the implementation of user-level asynchronous programming frameworks.
\item The resource management around the inheritance tree, kernel objects, and factory objects is designed to simplify the introduction of new kernel objects with minimal impact on the existing base kernel.
\end{itemize}


\section{Current Limitations}

\begin{itemize}
\item Capability transfers are not implemented. Instead the supervisor should manipulate the capabilities directly in the Capability Maps of supervised applications.
\end{itemize}
